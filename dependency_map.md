# Complete ThinkRL Dependency Map

## ðŸ“¦ External Dependencies

### Core Required Dependencies
```
torch>=2.0.0,<3.0.0
â”œâ”€â”€ Used by: ALL algorithm implementations
â”œâ”€â”€ Used by: ALL model implementations
â”œâ”€â”€ Used by: ALL training modules
â”œâ”€â”€ Used by: utils/checkpoint.py
â””â”€â”€ Used by: tests/*

numpy>=1.24.0,<2.0.0
â”œâ”€â”€ Used by: algorithms/* (numerical computations)
â”œâ”€â”€ Used by: data/processors.py
â”œâ”€â”€ Used by: evaluation/metrics.py
â””â”€â”€ Used by: utils/data.py
â””â”€â”€ Used by: tests/test_sample.py

pyyaml>=6.0,<7.0
â”œâ”€â”€ Used by: utils/checkpoint.py
â”œâ”€â”€ Used by: scripts/train.py
â”œâ”€â”€ Used by: scripts/evaluate.py
â””â”€â”€ Used by: configs/*.yaml parsing

tqdm>=4.65.0
â”œâ”€â”€ Used by: training/trainer.py
â”œâ”€â”€ Used by: data/loaders.py
â”œâ”€â”€ Used by: evaluation/evaluators.py
â””â”€â”€ Used by: scripts/*

accelerate>=0.21.0,<1.0.0
â”œâ”€â”€ Used by: training/distributed.py
â”œâ”€â”€ Used by: training/trainer.py
â”œâ”€â”€ Used by: utils/checkpoint.py
â””â”€â”€ Device management and distributed training
```

### Optional GPU Dependencies
```
cupy-cuda12x>=12.0.0,<13.0.0 (OR cupy-cuda11x>=11.0.0,<12.0.0)
â”œâ”€â”€ Used by: algorithms/dapo.py (GPU advantage computation)
â”œâ”€â”€ Used by: algorithms/vapo.py (GPU value estimation)
â”œâ”€â”€ Used by: utils/data.py (GPU data processing)
â””â”€â”€ Fallback to NumPy if not available
```

### ML Framework Dependencies
```
transformers>=4.30.0,<5.0.0
â”œâ”€â”€ Used by: models/gpt.py
â”œâ”€â”€ Used by: models/llama.py
â”œâ”€â”€ Used by: models/qwen.py
â”œâ”€â”€ Used by: training/trainer.py
â”œâ”€â”€ Used by: utils/tokenizers.py
â””â”€â”€ Dependencies: tokenizers, safetensors, datasets

peft>=0.4.0,<1.0.0
â”œâ”€â”€ Used by: models/base.py (PEFT integration)
â”œâ”€â”€ Used by: training/trainer.py (LoRA/QLoRA)
â””â”€â”€ Dependencies: bitsandbytes>=0.41.0

deepspeed>=0.9.0,<1.0.0
â”œâ”€â”€ Used by: training/distributed.py
â”œâ”€â”€ Used by: scripts/train.py (--deepspeed flag)
â””â”€â”€ ZeRO optimization stages

datasets>=2.14.0,<3.0.0
â”œâ”€â”€ Used by: data/datasets.py
â”œâ”€â”€ Used by: data/loaders.py
â””â”€â”€ HuggingFace dataset integration

safetensors>=0.3.0
â”œâ”€â”€ Used by: utils/checkpoint.py
â””â”€â”€ Safe model serialization

tokenizers>=0.15.0,<1.0.0
â”œâ”€â”€ Used by: utils/tokenizers.py
â”œâ”€â”€ Used by: models/*
â””â”€â”€ Fast tokenization
```

### Multimodal Dependencies
```
Vision:
  pillow>=9.0.0,<11.0.0
  â”œâ”€â”€ Used by: models/multimodal.py
  â””â”€â”€ Used by: data/processors.py

  torchvision>=0.15.0,<1.0.0
  â”œâ”€â”€ Used by: models/multimodal.py
  â””â”€â”€ Used by: training/multimodal_trainer.py

  opencv-python>=4.5.0
  â”œâ”€â”€ Used by: data/processors.py
  â””â”€â”€ Used by: evaluation/benchmarks.py

Audio:
  torchaudio>=2.0.0,<3.0.0
  â”œâ”€â”€ Used by: models/multimodal.py
  â””â”€â”€ Used by: data/processors.py

  librosa>=0.10.0
  â”œâ”€â”€ Used by: data/processors.py
  â””â”€â”€ Audio feature extraction

  soundfile>=0.12.0
  â””â”€â”€ Used by: data/loaders.py
```

### Reasoning Dependencies
```
networkx>=3.1,<4.0
â”œâ”€â”€ Used by: reasoning/tot/tree.py
â””â”€â”€ Tree structure management

graphviz>=0.20.0
â”œâ”€â”€ Used by: reasoning/tot/tree.py
â””â”€â”€ Tree visualization

matplotlib>=3.5.0
â”œâ”€â”€ Used by: evaluation/benchmarks.py
â”œâ”€â”€ Used by: utils/metrics.py
â””â”€â”€ Plotting and visualization

sympy>=1.12.0
â”œâ”€â”€ Used by: reasoning/cot/cot.py
â””â”€â”€ Symbolic math for reasoning

scipy>=1.10.0
â”œâ”€â”€ Used by: evaluation/metrics.py
â””â”€â”€ Statistical computations
```

### Experiment Tracking Dependencies
```
wandb>=0.15.0,<1.0.0
â”œâ”€â”€ Used by: training/trainer.py
â”œâ”€â”€ Used by: utils/logging.py
â””â”€â”€ Weights & Biases integration

tensorboard>=2.13.0
â”œâ”€â”€ Used by: training/trainer.py
â”œâ”€â”€ Used by: utils/logging.py
â””â”€â”€ TensorBoard logging

mlflow>=2.5.0,<3.0.0
â”œâ”€â”€ Used by: training/trainer.py
â””â”€â”€ MLflow experiment tracking
```

### Development Dependencies
```
Testing:
  pytest>=7.0.0,<8.0.0
  pytest-cov>=4.1.0,<5.0.0
  pytest-xdist>=3.3.0
  pytest-mock>=3.11.0

Code Quality:
  black>=23.9.0,<24.0.0
  isort>=5.12.0,<6.0.0
  flake8>=6.0.0,<7.0.0
  mypy>=1.5.0,<2.0.0
  pre-commit>=3.0.0,<4.0.0
```

## ðŸ—ï¸ Internal Dependencies

### Level 0: Foundation (No Internal Dependencies)

```python
# Base Classes and Protocols
thinkrl/algorithms/base.py
â”œâ”€â”€ Classes: AlgorithmConfig, BaseAlgorithm, AlgorithmOutput, AlgorithmRegistry
â”œâ”€â”€ External: torch, logging, warnings, dataclasses, typing
â””â”€â”€ Internal: None

thinkrl/models/base.py
â”œâ”€â”€ Classes: BaseModel, ModelConfig, ModelProtocol
â”œâ”€â”€ External: torch, torch.nn, typing
â””â”€â”€ Internal: None

thinkrl/reasoning/config.py
â”œâ”€â”€ Classes: ReasoningConfig
â”œâ”€â”€ External: dataclasses, typing
â””â”€â”€ Internal: None

# Utilities (Independent)
thinkrl/utils/logging.py
â”œâ”€â”€ Functions: setup_logger, get_logger
â”œâ”€â”€ External: logging, sys
â””â”€â”€ Internal: None

thinkrl/utils/metrics.py
â”œâ”€â”€ Functions: compute_metrics, aggregate_metrics
â”œâ”€â”€ External: numpy, torch, typing
â””â”€â”€ Internal: None

thinkrl/utils/data.py
â”œâ”€â”€ Functions: create_dataloader, preprocess_data
â”œâ”€â”€ External: torch, numpy
â””â”€â”€ Internal: None

thinkrl/utils/tokenizers.py
â”œâ”€â”€ Functions: get_tokenizer, tokenize_batch
â”œâ”€â”€ External: transformers (optional)
â””â”€â”€ Internal: None

thinkrl/utils/checkpoint.py
â”œâ”€â”€ Functions: save_checkpoint, load_checkpoint
â”œâ”€â”€ External: torch, pathlib, safetensors (optional)
â””â”€â”€ Internal: None
```

### Level 1: Core Implementations

```python
# Algorithm Implementations
thinkrl/algorithms/dapo.py
â”œâ”€â”€ Classes: DAPO, DAPOConfig, DAPOAdvantageEstimator, DAPOLoss, DAPOSampler
â”œâ”€â”€ External: torch, torch.nn.functional, logging, math
â”œâ”€â”€ Internal: from .base import AlgorithmConfig, AlgorithmOutput, BaseAlgorithm
â””â”€â”€ Exports: DAPO, DAPOConfig, create_dapo_algorithm, create_dapo_config

thinkrl/algorithms/grpo.py
â”œâ”€â”€ Classes: GRPO, GRPOConfig, GRPORewardNormalizer, GRPOLoss, GRPOBatcher
â”œâ”€â”€ External: torch, torch.nn.functional, collections.defaultdict
â”œâ”€â”€ Internal: from .base import AlgorithmConfig, AlgorithmOutput, BaseAlgorithm
â””â”€â”€ Exports: GRPO, GRPOConfig

thinkrl/algorithms/ppo.py
â”œâ”€â”€ Classes: PPO, PPOConfig, PPOAdvantageEstimator, PPOValueFunction, PPOLoss
â”œâ”€â”€ External: torch, torch.nn, torch.nn.functional, random
â”œâ”€â”€ Internal: from .base import AlgorithmConfig, AlgorithmOutput, BaseAlgorithm
â””â”€â”€ Exports: PPO, PPOConfig, create_ppo_algorithm, create_ppo_config

thinkrl/algorithms/reinforce.py
â”œâ”€â”€ Classes: REINFORCE, REINFORCEConfig, REINFORCEReturns, REINFORCEBaseline, REINFORCELoss
â”œâ”€â”€ External: torch, torch.nn, torch.nn.functional
â”œâ”€â”€ Internal: from .base import AlgorithmConfig, AlgorithmOutput, BaseAlgorithm
â””â”€â”€ Exports: REINFORCE, REINFORCEConfig, create_reinforce_algorithm

thinkrl/algorithms/vapo.py
â”œâ”€â”€ Classes: VAPO, VAPOConfig (placeholder)
â”œâ”€â”€ External: torch
â”œâ”€â”€ Internal: from .base import AlgorithmConfig, AlgorithmOutput, BaseAlgorithm
â””â”€â”€ Exports: VAPO, VAPOConfig

# Model Implementations
thinkrl/models/gpt.py
â”œâ”€â”€ Classes: GPTModel, GPTConfig
â”œâ”€â”€ External: torch, torch.nn, transformers (optional)
â”œâ”€â”€ Internal: from .base import BaseModel, ModelConfig
â””â”€â”€ Exports: GPTModel, GPTConfig

thinkrl/models/llama.py
â”œâ”€â”€ Classes: LlamaModel, LlamaConfig
â”œâ”€â”€ External: torch, torch.nn, transformers (optional)
â”œâ”€â”€ Internal: from .base import BaseModel, ModelConfig
â””â”€â”€ Exports: LlamaModel, LlamaConfig

thinkrl/models/qwen.py
â”œâ”€â”€ Classes: QwenModel, QwenConfig
â”œâ”€â”€ External: torch, torch.nn, transformers (optional)
â”œâ”€â”€ Internal: from .base import BaseModel, ModelConfig
â””â”€â”€ Exports: QwenModel, QwenConfig

thinkrl/models/multimodal.py
â”œâ”€â”€ Classes: MultimodalModel, MultimodalConfig
â”œâ”€â”€ External: torch, torch.nn, torchvision, torchaudio (optional)
â”œâ”€â”€ Internal: from .base import BaseModel, ModelConfig
â””â”€â”€ Exports: MultimodalModel, MultimodalConfig

# Data Layer
thinkrl/data/datasets.py
â”œâ”€â”€ Classes: RLHFDataset, PreferenceDataset
â”œâ”€â”€ External: torch.utils.data, datasets (optional)
â”œâ”€â”€ Internal: from ..utils.data import preprocess_data
â””â”€â”€ Exports: RLHFDataset, PreferenceDataset

thinkrl/data/processors.py
â”œâ”€â”€ Functions: process_text, process_image, process_audio
â”œâ”€â”€ External: numpy, pillow, librosa (optional)
â”œâ”€â”€ Internal: from ..utils.data import *
â””â”€â”€ Exports: process_text, process_image, process_audio

# Evaluation Layer
thinkrl/evaluation/metrics.py
â”œâ”€â”€ Functions: compute_reward, compute_kl_divergence, compute_accuracy
â”œâ”€â”€ External: torch, numpy, scipy (optional)
â”œâ”€â”€ Internal: from ..utils.metrics import *
â””â”€â”€ Exports: compute_reward, compute_kl_divergence

# Reasoning Components
thinkrl/reasoning/cot/prompts.py
â”œâ”€â”€ Constants: COT_PROMPTS, COT_TEMPLATES
â”œâ”€â”€ External: None
â”œâ”€â”€ Internal: None
â””â”€â”€ Exports: COT_PROMPTS, COT_TEMPLATES

thinkrl/reasoning/cot/cot.py
â”œâ”€â”€ Classes: ChainOfThought, CoTConfig
â”œâ”€â”€ External: torch, sympy (optional)
â”œâ”€â”€ Internal: 
â”‚   from ..config import ReasoningConfig
â”‚   from .prompts import COT_PROMPTS
â””â”€â”€ Exports: ChainOfThought, CoTConfig

thinkrl/reasoning/tot/tree.py
â”œâ”€â”€ Classes: ThoughtTree, TreeNode
â”œâ”€â”€ External: networkx, graphviz (optional)
â”œâ”€â”€ Internal: None
â””â”€â”€ Exports: ThoughtTree, TreeNode

thinkrl/reasoning/tot/evaluator.py
â”œâ”€â”€ Classes: ThoughtEvaluator
â”œâ”€â”€ External: torch
â”œâ”€â”€ Internal: from .tree import TreeNode
â””â”€â”€ Exports: ThoughtEvaluator

thinkrl/reasoning/tot/tot.py
â”œâ”€â”€ Classes: TreeOfThought, ToTConfig
â”œâ”€â”€ External: torch
â”œâ”€â”€ Internal:
â”‚   from ..config import ReasoningConfig
â”‚   from .tree import ThoughtTree
â”‚   from .evaluator import ThoughtEvaluator
â””â”€â”€ Exports: TreeOfThought, ToTConfig
```

### Level 2: Aggregation and Orchestration

```python
# Algorithm Module Init
thinkrl/algorithms/__init__.py
â”œâ”€â”€ External: typing
â”œâ”€â”€ Internal:
â”‚   from .base import AlgorithmConfig, BaseAlgorithm
â”‚   from .dapo import DAPO, DAPOConfig
â”‚   from .grpo import GRPO, GRPOConfig
â”‚   from .ppo import PPO, PPOConfig
â”‚   from .reinforce import REINFORCE, REINFORCEConfig
â”‚   from .vapo import VAPO, VAPOConfig
â”œâ”€â”€ Functions: get_algorithm(), list_algorithms(), create_algorithm()
â””â”€â”€ Exports: All algorithm classes and configs

# Data Module
thinkrl/data/loaders.py
â”œâ”€â”€ Classes: RLHFDataLoader
â”œâ”€â”€ External: torch.utils.data
â”œâ”€â”€ Internal:
â”‚   from .datasets import RLHFDataset, PreferenceDataset
â”‚   from .processors import process_text
â”‚   from ..utils.data import create_dataloader
â””â”€â”€ Exports: RLHFDataLoader

# Evaluation Module
thinkrl/evaluation/evaluators.py
â”œâ”€â”€ Classes: RLHFEvaluator
â”œâ”€â”€ External: torch, tqdm
â”œâ”€â”€ Internal:
â”‚   from .metrics import compute_reward, compute_accuracy
â”‚   from ..utils.metrics import aggregate_metrics
â””â”€â”€ Exports: RLHFEvaluator

# Registry System
thinkrl/registry/algorithms.py
â”œâ”€â”€ Functions: register_algorithm, get_registered_algorithms
â”œâ”€â”€ External: typing
â”œâ”€â”€ Internal:
â”‚   from ..algorithms.base import BaseAlgorithm
â”‚   from ..algorithms import *
â””â”€â”€ Manages dynamic algorithm registration

thinkrl/registry/models.py
â”œâ”€â”€ Functions: register_model, get_registered_models
â”œâ”€â”€ External: typing
â”œâ”€â”€ Internal:
â”‚   from ..models.base import BaseModel
â”‚   from ..models import *
â””â”€â”€ Manages dynamic model registration
```

### Level 3: Training and Integration

```python
# Core Trainer
thinkrl/training/trainer.py
â”œâ”€â”€ Classes: RLHFTrainer, TrainerConfig
â”œâ”€â”€ External: torch, tqdm, wandb/tensorboard (optional)
â”œâ”€â”€ Internal:
â”‚   from ..algorithms import get_algorithm
â”‚   from ..models.base import ModelProtocol
â”‚   from ..data.loaders import RLHFDataLoader
â”‚   from ..evaluation.evaluators import RLHFEvaluator
â”‚   from ..utils.logging import get_logger
â”‚   from ..utils.checkpoint import save_checkpoint, load_checkpoint
â”‚   from ..utils.metrics import aggregate_metrics
â””â”€â”€ Exports: RLHFTrainer, TrainerConfig

# Distributed Training
thinkrl/training/distributed.py
â”œâ”€â”€ Classes: DistributedTrainer
â”œâ”€â”€ External: torch.distributed, accelerate, deepspeed (optional)
â”œâ”€â”€ Internal:
â”‚   from .trainer import RLHFTrainer, TrainerConfig
â”‚   from ..utils.logging import get_logger
â””â”€â”€ Exports: DistributedTrainer

# Specialized Trainers
thinkrl/training/cot_trainer.py
â”œâ”€â”€ Classes: CoTTrainer
â”œâ”€â”€ External: torch
â”œâ”€â”€ Internal:
â”‚   from .trainer import RLHFTrainer
â”‚   from ..reasoning.cot import ChainOfThought, CoTConfig
â”‚   from ..algorithms import get_algorithm
â””â”€â”€ Exports: CoTTrainer

thinkrl/training/tot_trainer.py
â”œâ”€â”€ Classes: ToTTrainer
â”œâ”€â”€ External: torch
â”œâ”€â”€ Internal:
â”‚   from .trainer import RLHFTrainer
â”‚   from ..reasoning.tot import TreeOfThought, ToTConfig
â”‚   from ..algorithms import get_algorithm
â””â”€â”€ Exports: ToTTrainer

thinkrl/training/multimodal_trainer.py
â”œâ”€â”€ Classes: MultimodalTrainer
â”œâ”€â”€ External: torch, torchvision
â”œâ”€â”€ Internal:
â”‚   from .trainer import RLHFTrainer
â”‚   from ..models.multimodal import MultimodalModel
â”‚   from ..data.processors import process_image, process_audio
â””â”€â”€ Exports: MultimodalTrainer

# Evaluation Integration
thinkrl/evaluation/benchmarks.py
â”œâ”€â”€ Classes: BenchmarkSuite, AIFEBenchmark
â”œâ”€â”€ External: torch, matplotlib (optional)
â”œâ”€â”€ Internal:
â”‚   from .evaluators import RLHFEvaluator
â”‚   from .metrics import compute_reward, compute_accuracy
â”‚   from ..utils.metrics import aggregate_metrics
â””â”€â”€ Exports: BenchmarkSuite, AIFEBenchmark
```

### Level 4: Entry Points and Scripts

```python
# Main Training Script
thinkrl/scripts/train.py
â”œâ”€â”€ External: argparse, yaml, torch
â”œâ”€â”€ Internal:
â”‚   from ..training.trainer import RLHFTrainer, TrainerConfig
â”‚   from ..training.distributed import DistributedTrainer
â”‚   from ..algorithms import create_algorithm, get_algorithm_config
â”‚   from ..models import get_model  # Would be in models/__init__.py
â”‚   from ..data.loaders import RLHFDataLoader
â”‚   from ..utils.logging import setup_logger
â”‚   from ..utils.checkpoint import load_checkpoint
â”œâ”€â”€ Entry point: main()
â””â”€â”€ CLI: thinkrl-train

# Evaluation Script
thinkrl/scripts/evaluate.py
â”œâ”€â”€ External: argparse, torch
â”œâ”€â”€ Internal:
â”‚   from ..evaluation.evaluators import RLHFEvaluator
â”‚   from ..evaluation.benchmarks import BenchmarkSuite
â”‚   from ..models import get_model
â”‚   from ..utils.checkpoint import load_checkpoint
â”‚   from ..utils.logging import setup_logger
â”œâ”€â”€ Entry point: main()
â””â”€â”€ CLI: thinkrl-eval

# Chain of Thought Script
thinkrl/scripts/chain_of_thought.py
â”œâ”€â”€ External: argparse, torch
â”œâ”€â”€ Internal:
â”‚   from ..training.cot_trainer import CoTTrainer
â”‚   from ..reasoning.cot import ChainOfThought, CoTConfig
â”‚   from ..models import get_model
â”‚   from ..utils.logging import setup_logger
â”œâ”€â”€ Entry point: main()
â””â”€â”€ CLI: thinkrl-cot

# Tree of Thought Script
thinkrl/scripts/tree_of_thought.py
â”œâ”€â”€ External: argparse, torch
â”œâ”€â”€ Internal:
â”‚   from ..training.tot_trainer import ToTTrainer
â”‚   from ..reasoning.tot import TreeOfThought, ToTConfig
â”‚   from ..models import get_model
â”‚   from ..utils.logging import setup_logger
â”œâ”€â”€ Entry point: main()
â””â”€â”€ CLI: thinkrl-tot

# Multimodal Training Script
thinkrl/scripts/multimodal_train.py
â”œâ”€â”€ External: argparse, torch
â”œâ”€â”€ Internal:
â”‚   from ..training.multimodal_trainer import MultimodalTrainer
â”‚   from ..models.multimodal import MultimodalModel
â”‚   from ..data.processors import process_image, process_audio
â”‚   from ..utils.logging import setup_logger
â”œâ”€â”€ Entry point: main()
â””â”€â”€ CLI: thinkrl-multimodal
```

### Test Dependencies

```python
# Test Infrastructure
tests/__init__.py
â”œâ”€â”€ External: pytest
â””â”€â”€ Internal: None

tests/test_sample.py
â”œâ”€â”€ External: pytest, torch, numpy
â”œâ”€â”€ Internal: from thinkrl import __version__
â””â”€â”€ Tests basic imports and operations

# Base Test Utilities
tests/test_algorithms/base.py
â”œâ”€â”€ Classes: AlgorithmConfig, BaseAlgorithm, MockModel
â”œâ”€â”€ External: pytest, torch, mock
â”œâ”€â”€ Internal: None (defines mocks)
â””â”€â”€ Exports: Test utilities for algorithm testing

tests/test_models/__init__.py
â”œâ”€â”€ Classes: MockModel, MockValueModel
â”œâ”€â”€ External: torch, torch.nn
â”œâ”€â”€ Internal: None (defines mocks)
â””â”€â”€ Exports: Test utilities for model testing

# Algorithm Tests
tests/test_algorithms/test_dapo.py
â”œâ”€â”€ External: pytest, torch, mock
â”œâ”€â”€ Internal:
â”‚   from tests.test_models import MockModel, create_dummy_batch
â”‚   from thinkrl.algorithms.base import AlgorithmOutput
â”‚   from thinkrl.algorithms.dapo import *
â””â”€â”€ Tests DAPO implementation

tests/test_algorithms/test_grpo.py
â”œâ”€â”€ External: pytest, torch
â”œâ”€â”€ Internal:
â”‚   from tests.test_models import MockModel, create_dummy_batch
â”‚   from thinkrl.algorithms.base import AlgorithmOutput
â”‚   from thinkrl.algorithms.grpo import *
â””â”€â”€ Tests GRPO implementation

tests/test_algorithms/test_ppo.py
â”œâ”€â”€ External: pytest, torch
â”œâ”€â”€ Internal:
â”‚   from tests.test_models import MockModel, create_dummy_batch
â”‚   from thinkrl.algorithms.base import AlgorithmOutput
â”‚   from thinkrl.algorithms.ppo import *
â””â”€â”€ Tests PPO implementation

tests/test_algorithms/test_reinforce.py
â”œâ”€â”€ External: pytest, torch
â”œâ”€â”€ Internal:
â”‚   from tests.test_models import MockModel, create_dummy_batch
â”‚   from thinkrl.algorithms.reinforce import *
â””â”€â”€ Tests REINFORCE implementation

# Model Tests
tests/test_models/test_base.py
â”œâ”€â”€ External: pytest, torch, mock
â”œâ”€â”€ Internal:
â”‚   from tests.test_models import MockModel, ModelTestConfig
â”‚   from thinkrl.models.base import BaseModel, ModelProtocol (if exists)
â””â”€â”€ Tests base model functionality
```

## ðŸ“Š Dependency Statistics

### External Dependencies Count:
- **Core Required**: 5 packages
- **Optional GPU**: 2 packages (cupy variants)
- **ML Frameworks**: 7 packages
- **Multimodal**: 6 packages
- **Reasoning**: 5 packages
- **Monitoring**: 4 packages
- **Development**: 9 packages
- **Total Unique**: ~38 packages

### Internal Module Dependencies:
- **Level 0 (Foundation)**: 7 modules
- **Level 1 (Core)**: 24 modules
- **Level 2 (Aggregation)**: 8 modules
- **Level 3 (Training)**: 6 modules
- **Level 4 (Scripts)**: 5 modules
- **Test Modules**: 12 modules
- **Total Internal Modules**: ~62 modules

### Dependency Depth:
- **Maximum depth**: 4 levels
- **Average depth**: 2.3 levels
- **Circular dependencies**: 0

### Most Depended Upon (Internal):
1. `algorithms/base.py` - Used by 6 algorithm implementations
2. `utils/*` modules - Used throughout the codebase
3. `models/base.py` - Used by 4 model implementations
4. `training/trainer.py` - Used by 4 specialized trainers
5. `evaluation/metrics.py` - Used by evaluators and benchmarks

### Least Dependencies (Most Independent):
1. All `utils/*` modules - No internal dependencies
2. `reasoning/config.py` - No internal dependencies
3. `algorithms/base.py` - No internal dependencies
4. `models/base.py` - No internal dependencies
5. Prompt templates and constants

### Critical Path Dependencies:
```
scripts/train.py
â””â”€â”€ training/trainer.py
    â”œâ”€â”€ algorithms/__init__.py
    â”‚   â””â”€â”€ algorithms/*.py
    â”‚       â””â”€â”€ algorithms/base.py
    â”œâ”€â”€ models/*.py
    â”‚   â””â”€â”€ models/base.py
    â””â”€â”€ utils/*.py
```

This architecture ensures:
- **Modularity**: Each component can be developed and tested independently
- **Extensibility**: New algorithms/models can be added without modifying existing code
- **Maintainability**: Clear separation of concerns with no circular dependencies
- **Testability**: Mock implementations allow isolated testing
- **Performance**: Optional dependencies allow lightweight installations